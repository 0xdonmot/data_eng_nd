{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "import cassandra\n",
    "import os\n",
    "import csv\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from cassandra.query import UNSET_VALUE\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "- This project extracts data from four csv files, explores and cleans them, then loads them to a Apache Cassandra cluster.\n",
    "- The project is meant to define all the building blocks to fully automate this process by spinning up a cluster in the cloud and incorporating Airflow. As such, the full data was not loaded into the Cassandra cluster created.\n",
    "- The end solution is a Cassandra keyspace optimised for particular queries. The script would need to be adjusted if other types of queries would be more relevant.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "The project uses four datasets:\n",
    "- I94 Immigration Data: This data comes from the US National Tourism and Trade Office. More information can be found [here](https://www.trade.gov/national-travel-and-tourism-office).\n",
    "- World Temperature Data: This dataset came from Kaggle. More information can be found [here](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "- U.S. City Demographic Data: This data comes from OpenSoft. More information can be found [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "- Airport Code Table: This is a simple table of airport codes and corresponding cities. More information can be found [here](https://datahub.io/core/airport-codes#data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration Data Dictionary\n",
    "\n",
    "- I94YR - 4 digit year\n",
    "- I94MON - Numeric month\n",
    "- I94CIT & I94RES - This format shows all the valid and invalid codes for processing\n",
    "- I94PORT - This format shows all the valid and invalid codes for processing value $i94prtl\n",
    "- ARRDATE is the Arrival Date in the USA. It is a SAS date numeric field that a \n",
    "   permament format has not been applied.  Please apply whichever date format \n",
    "   works for you.\n",
    "- I94MODE - There are missing values as well as not reported (9) value i94model\n",
    "    - 1 = 'Air'\n",
    "    - 2 = 'Sea'\n",
    "    - 3 = 'Land'\n",
    "    - 9 = 'Not reported'\n",
    "- I94ADDR - There is lots of invalid codes in this variable and the list below \n",
    "   shows what we have found to be valid, everything else goes into 'other'\n",
    "- DEPDATE is the Departure Date from the USA. It is a SAS date numeric field that \n",
    "   a permament format has not been applied.\n",
    "- I94BIR - Age of Respondent in Years\n",
    "- I94VISA - Visa codes collapsed into three categories:\n",
    "   - Business\n",
    "   - Pleasure\n",
    "   - Student\n",
    "- COUNT - Used for summary statistics\n",
    "- DTADFILE - Character Date Field - Date added to I-94 Files - CIC does not use\n",
    "- VISAPOST - Department of State where where Visa was issued - CIC does not use\n",
    "- OCCUP - Occupation that will be performed in U.S. - CIC does not use\n",
    "- ENTDEPA - Arrival Flag - admitted or paroled into the U.S. - CIC does not use\n",
    "- ENTDEPD - Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\n",
    "- ENTDEPU - Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\n",
    "- MATFLAG - Match flag - Match of arrival and departure records\n",
    "- BIRYEAR - 4 digit year of birth\n",
    "- DTADDTO - Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use\n",
    "- GENDER - Non-immigrant sex\n",
    "- INSNUM - INS number\n",
    "- AIRLINE - Airline used to arrive in U.S.\n",
    "- ADMNUM - Admission Number\n",
    "- FLTNO - Flight number of Airline used to arrive in U.S.\n",
    "- VISATYPE - Class of admission legally admitting the non-immigrant to temporarily stay in U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's read and explore some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in sample data\n",
    "immigration_data = pd.read_csv('immigration_data_sample.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2027561</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171295</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589494</th>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631158</th>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032257</th>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0      1.0   \n",
       "2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0      1.0   \n",
       "589494   1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0      1.0   \n",
       "2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0      1.0   \n",
       "3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0      3.0   \n",
       "\n",
       "        i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "2027561      HI  20573.0   ...         NaN        M   1955.0  07202016      F   \n",
       "2171295      TX  20568.0   ...         NaN        M   1990.0  10222016      M   \n",
       "589494       FL  20571.0   ...         NaN        M   1940.0  07052016      M   \n",
       "2631158      CA  20581.0   ...         NaN        M   1991.0  10272016      M   \n",
       "3032257      NY  20553.0   ...         NaN        M   1997.0  07042016      F   \n",
       "\n",
       "        insnum airline        admnum  fltno visatype  \n",
       "2027561    NaN      JL  5.658267e+10  00782       WT  \n",
       "2171295    NaN     *GA  9.436200e+10  XBLNG       B2  \n",
       "589494     NaN      LH  5.578047e+10  00464       WT  \n",
       "2631158    NaN      QR  9.478970e+10  00739       B2  \n",
       "3032257    NaN     NaN  4.232257e+10   LAND       WT  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate',\n",
       "       'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count',\n",
       "       'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu',\n",
       "       'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline',\n",
       "       'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Initialise Spark and load datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialise spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "immigration_data=spark.read.parquet(\"sas_data\")\n",
    "temperature_data = spark.read.option('header', True).csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "us_demographic_data = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "airport_code_data = pd.read_csv('airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore and Clean the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def missing_cols(df, vertical=True):\n",
    "    \"\"\" \n",
    "    This function counts and displays missing values for each column in the \n",
    "    passed dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_missing = df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c))\n",
    "                     .alias(c) for c in df.columns]).toPandas()\n",
    "    print(pd.melt(df_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    variable    value\n",
      "0      cicid        0\n",
      "1      i94yr        0\n",
      "2     i94mon        0\n",
      "3     i94cit        0\n",
      "4     i94res        0\n",
      "5    i94port        0\n",
      "6    arrdate        0\n",
      "7    i94mode      239\n",
      "8    i94addr   152592\n",
      "9    depdate   142457\n",
      "10    i94bir      802\n",
      "11   i94visa        0\n",
      "12     count        0\n",
      "13  dtadfile        1\n",
      "14  visapost  1881250\n",
      "15     occup  3088187\n",
      "16   entdepa      238\n",
      "17   entdepd   138429\n",
      "18   entdepu  3095921\n",
      "19   matflag   138429\n",
      "20   biryear      802\n",
      "21   dtaddto      477\n",
      "22    gender   414269\n",
      "23    insnum  2982605\n",
      "24   airline    83627\n",
      "25    admnum        0\n",
      "26     fltno    19549\n",
      "27  visatype        0\n"
     ]
    }
   ],
   "source": [
    "# check for missing columns\n",
    "missing_cols(immigration_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate values\n",
    "immigration_data.count() - immigration_data.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Schema looks good, apart from the date columns.\n",
    "Let's update these types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# define sas to spark date type udf\n",
    "parse_date = F.udf(lambda x: pd.to_timedelta(x, unit='D') + pd.Timestamp('1960-1-1') if x is not None else x\n",
    "                   , DateType())\n",
    "\n",
    "# update type of date columns\n",
    "immigration_data = immigration_data.withColumn('arrdate', parse_date('arrdate'))\n",
    "immigration_data = immigration_data.withColumn('depdate', parse_date('depdate'))\n",
    "immigration_data = immigration_data.withColumn('dtaddto', F.to_date('dtaddto', \"MMddyyyy\"))\n",
    "immigration_data = immigration_data.withColumn('dtadfile', F.to_date('dtadfile', \"yyyyMMdd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port     arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "\n",
       "  i94addr     depdate   ...     entdepu  matflag  biryear     dtaddto gender  \\\n",
       "0      CA  2016-05-08   ...        None        M   1976.0  2016-10-29      F   \n",
       "1      NV  2016-05-17   ...        None        M   1984.0  2016-10-29      F   \n",
       "2      WA  2016-05-08   ...        None        M   1987.0  2016-10-29      M   \n",
       "3      WA  2016-05-14   ...        None        M   1987.0  2016-10-29      F   \n",
       "4      WA  2016-05-14   ...        None        M   1988.0  2016-10-29      M   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      QF  9.495387e+10  00011       B1  \n",
       "1   None      VA  9.495562e+10  00007       B1  \n",
       "2   None      DL  9.495641e+10  00040       B1  \n",
       "3   None      DL  9.495645e+10  00040       B1  \n",
       "4   None      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check change\n",
    "immigration_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Looks good. Let's load and explore the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01               None                          None  Århus   \n",
       "2  1744-01-01               None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        variable   value\n",
      "0                             dt       0\n",
      "1             AverageTemperature  364130\n",
      "2  AverageTemperatureUncertainty  364130\n",
      "3                           City       0\n",
      "4                        Country       0\n",
      "5                       Latitude       0\n",
      "6                      Longitude       0\n"
     ]
    }
   ],
   "source": [
    "missing_cols(temperature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data starts at 1743 and has 8m rows! Let's filter from 2010 onwards. We will need to convert to date format first to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert to date type\n",
    "temperature_data = temperature_data.withColumn('dt', F.to_date('dt', \"yyyy-MM-dd\"))\n",
    "\n",
    "# filter data after year 2010\n",
    "temperature_data = temperature_data.filter(temperature_data.dt > F.lit(\"2010-01-01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>-22.308000000000003</td>\n",
       "      <td>0.517</td>\n",
       "      <td>Öskemen</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>50.63N</td>\n",
       "      <td>82.39E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>-2.6910000000000003</td>\n",
       "      <td>0.272</td>\n",
       "      <td>Aalborg</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>-13.356</td>\n",
       "      <td>2.379</td>\n",
       "      <td>Ürümqi</td>\n",
       "      <td>China</td>\n",
       "      <td>44.20N</td>\n",
       "      <td>87.20E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>5.252000000000001</td>\n",
       "      <td>0.41700000000000004</td>\n",
       "      <td>Çorum</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>34.08E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>8.789</td>\n",
       "      <td>0.366</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt   AverageTemperature AverageTemperatureUncertainty      City  \\\n",
       "0  2010-02-01  -22.308000000000003                         0.517   Öskemen   \n",
       "1  2010-02-01  -2.6910000000000003                         0.272   Aalborg   \n",
       "2  2010-02-01              -13.356                         2.379    Ürümqi   \n",
       "3  2010-02-01    5.252000000000001           0.41700000000000004     Çorum   \n",
       "4  2010-02-01                8.789                         0.366  A Coruña   \n",
       "\n",
       "      Country Latitude Longitude  \n",
       "0  Kazakhstan   50.63N    82.39E  \n",
       "1     Denmark   57.05N    10.33E  \n",
       "2       China   44.20N    87.20E  \n",
       "3      Turkey   40.99N    34.08E  \n",
       "4       Spain   42.59N     8.73W  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check change\n",
    "temperature_data.orderBy('dt').limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data.count() - temperature_data.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "2         Hoover        Alabama        38.5          38040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  \n",
       "2                    2.58         AL               Asian   4759  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_demographic_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "us_demographic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_demographic_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft continent  \\\n",
       "0   00A       heliport     Total Rf Heliport          11.0       NaN   \n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0       NaN   \n",
       "2  00AK  small_airport          Lowell Field         450.0       NaN   \n",
       "\n",
       "  iso_country iso_region  municipality gps_code iata_code local_code  \\\n",
       "0          US      US-PA      Bensalem      00A       NaN        00A   \n",
       "1          US      US-KS         Leoti     00AA       NaN       00AA   \n",
       "2          US      US-AK  Anchor Point     00AK       NaN       00AK   \n",
       "\n",
       "                          coordinates  \n",
       "0  -74.93360137939453, 40.07080078125  \n",
       "1              -101.473911, 38.704022  \n",
       "2         -151.695999146, 59.94919968  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "airport_code_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.1 Conceptual Data Model\n",
    "\n",
    "\n",
    "The data does not seem very relatable. The only relations I can think of that might be relevant are:\n",
    "1. Analysing immigration statistics by temperature on the date.\n",
    "2. Relating states/cities that experience the most immigration to the demographic make-up\n",
    "3. Relating immigration statistics to the location and type of airport.\n",
    "\n",
    "Out of these relations, only the second one makes remote sense to me.\n",
    "\n",
    "It therefore seems more likely that these tables are unrelated. In addition, immigration statistics data is already very large (i.e. 3m rows), yet it only contains data for April 2016. If this database takes in data from other months, it's size will increase quickly.\n",
    "\n",
    "As a result, I believe an Apache Cassandra database format would be more appropriate than a SQL relational database structure. This gives the flexibility to allow the database to consistently scale and work with large amounts of data. For relational use cases (e.g. point 2 listed above), the data would need to be pulled to the client node before performing analysis.\n",
    "\n",
    "Cassandra is optimised to store very large amounts of data. As such, I believe it should be okay to store rows with null values. This is why they have not been cleaned above.\n",
    "\n",
    "### 3.2 Mapping Out Data Pipeline\n",
    "\n",
    "\n",
    "The following steps will need to be undertaken:\n",
    "- write files locally\n",
    "- initialise and connect to a Cassandra cluster\n",
    "- crate a keyspace\n",
    "- create tables and insert data into them\n",
    "\n",
    "A note on 'null' data insertion in Cassandra. Cassandra does not allow for null values to be inserted and instead replaces them with tombstone values. Down the line, this can cause performance issues and higher query latency. During a scan, Cassandra keeps tombstones in memory and returns them to the coordinator node, which uses them to ensure other replica nodes also know about the deleted rows. It is preferable to simply not insert data in such instances. So, the insertion script will need to check for null rows and adjust the query accordingly before insertion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Check for duplicates in planned primary key columns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data.count() - immigration_data.dropDuplicates(['i94port', 'i94cit', 'arrdate', 'cicid']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data.count() - temperature_data.dropDuplicates(['dt', 'City', 'Country']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "temperature_data = temperature_data.dropDuplicates(['dt', 'City', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check change\n",
    "temperature_data.count() - temperature_data.dropDuplicates(['dt', 'City', 'Country']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_demographic_data.duplicated(subset=['Race', 'City', 'State']).shape[0] - us_demographic_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_data.duplicated(subset=['iso_region', 'ident', 'type']).shape[0] - airport_code_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Reduce size of immigration file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter data\n",
    "immigration_data = immigration_data.filter(immigration_data.arrdate > F.lit(\"2016-04-29\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Save data locally_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write files to local storage\n",
    "path = 'clean_data/'\n",
    "\n",
    "\n",
    "immigration_data\\\n",
    "    .coalesce(1)\\\n",
    "    .write.option(\"header\",True)\\\n",
    "    .csv(path+\"immigration_data\")\n",
    "temperature_data\\\n",
    "    .coalesce(1)\\\n",
    "    .write.option(\"header\",True)\\\n",
    "    .csv(path+\"temperature_data\")\n",
    "us_demographic_data.to_csv(path+'us_demographic_data.csv', index=False)\n",
    "airport_code_data.to_csv(path+'airport_code_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Initialise Cassandra cluster and create keyspace_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "# specify port and make a connection to Cassandra instance\n",
    "port = ['127.0.0.1']\n",
    "cluster = Cluster(port)\n",
    "\n",
    "# establish a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will use a SimpleStrategy replication. This approach places the first replica on the node selected by the client. After that remaining replicas are placed in clockwise direction in the data center (collection of Cassandra nodes).\n",
    "\n",
    "A replication factor of 1 ensures that only one copy of each row will be stored in the Cassandra cluster.\n",
    "\n",
    "Both of these parameters could be changed depending on the level of fault tolerance desired in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f1f567aaba8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Keyspace\n",
    "\n",
    "session.execute(\"\"\"\n",
    "CREATE KEYSPACE IF NOT EXISTS us_immigration\n",
    "WITH REPLICATION = \n",
    "{'class': 'SimpleStrategy', 'replication_factor': 1}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set keyspace\n",
    "session.set_keyspace('us_immigration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Define column names and data types for each table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_columns = [\n",
    "        ('cic_id', 'int', string_to_int),\n",
    "        ('admission_year', 'int', string_to_int),\n",
    "        ('admission_month', 'int', string_to_int),\n",
    "        ('applicant_city', 'text', str),\n",
    "        ('applicant_residence', 'text', str),\n",
    "        ('application_port', 'text', str),\n",
    "        ('arrival_date', 'date', string_to_date),\n",
    "        ('applicant_arrival_mode', 'text', str),\n",
    "        ('port_state', 'text', str),\n",
    "        ('departure_date', 'date', string_to_date),\n",
    "        ('age', 'int', string_to_int),\n",
    "        ('visa_code', 'text', str),\n",
    "        ('count', 'int', string_to_int),\n",
    "        ('character_date', 'date', string_to_date),\n",
    "        ('visa_post', 'text', str),\n",
    "        ('occupation', 'text', str),\n",
    "        ('arrival_flag', 'text', str),\n",
    "        ('departure_flag', 'text', str),\n",
    "        ('update_flag', 'text', str),\n",
    "        ('match_flag', 'text', str),\n",
    "        ('birth_year', 'int', string_to_int),\n",
    "        ('date_admitted', 'date', string_to_date),\n",
    "        ('gender', 'text', str),\n",
    "        ('insurance_num', 'text', str),\n",
    "        ('airline', 'text', str),\n",
    "        ('admssion_number', 'text', str),\n",
    "        ('flight_no', 'text', str),\n",
    "        ('visa_type', 'text', str)\n",
    "        ]\n",
    "immigration_primary_keys = ['application_port', 'applicant_city', 'arrival_date', 'cic_id']\n",
    "\n",
    "\n",
    "temperature_columns = [\n",
    "    ('date', 'date', string_to_date), \n",
    "    ('average_temperature', 'float', float),\n",
    "    ('average_temperature_uncertainty', 'float', float),\n",
    "    ('city', 'text', str),\n",
    "    ('country', 'text', str),\n",
    "    ('latitude', 'text', str),\n",
    "    ('longitude', 'text', str)]\n",
    "temperature_primary_keys = ['country', 'date', 'city']\n",
    "\n",
    "us_demographic_columns = [\n",
    "    ('city', 'text', str), \n",
    "    ('state', 'text', str), \n",
    "    ('median_age', 'float', float), \n",
    "    ('male_population', 'int', string_to_int), \n",
    "    ('female_population', 'int', string_to_int),\n",
    "    ('total_population', 'int', string_to_int),\n",
    "    ('number_of_veterans', 'int', string_to_int),\n",
    "    ('foreign_born', 'int', string_to_int),\n",
    "    ('average_household_size', 'float', float), \n",
    "    ('state_code', 'text', str), \n",
    "    ('race', 'text', str), \n",
    "    ('count', 'int', string_to_int)]\n",
    "us_demographic_primary_keys = ['race', 'city', 'state']\n",
    "\n",
    "airport_code_columns = [\n",
    "    ('ident', 'text', str), \n",
    "    ('type', 'text', str), \n",
    "    ('name', 'text', str), \n",
    "    ('elevation_ft', 'float', float), \n",
    "    ('continent', 'text', str),\n",
    "    ('iso_country', 'text', str),\n",
    "    ('iso_region', 'text', str),\n",
    "    ('municipality', 'text', str),\n",
    "    ('gps_code', 'text', str), \n",
    "    ('iata_code', 'text', str), \n",
    "    ('local_code', 'text', str), \n",
    "    ('coordinates', 'text', str)]\n",
    "airport_code_primary_keys = ['iso_region', 'ident', 'type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Define table creation and insertion functions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# table creation function\n",
    "def create_table(table_name, columns, primary_keys):\n",
    "    \"\"\" \n",
    "    This function creates the individual tables within the us_immigration keyspace\n",
    "    and defines the columns and their types\n",
    "    \"\"\"\n",
    "    \n",
    "    # drop the table if it exists\n",
    "    query = f\"DROP TABLE IF EXISTS {table_name}\"\n",
    "    session.execute(query)\n",
    "    \n",
    "    # recreate the table using the defined schema\n",
    "    query = f\"CREATE TABLE IF NOT EXISTS {table_name}\"\n",
    "    \n",
    "    # insert columns into query\n",
    "    for col in columns:\n",
    "        beginning = '(' if col == columns[0] else ''\n",
    "        end = keys_query if col == columns[-1] else ','\n",
    "        query += f\" {beginning}{col[0]} {col[1]},\"\n",
    "        \n",
    "     # create primary keys\n",
    "    keys_query = 'PRIMARY KEY'\n",
    "    for key in primary_keys:\n",
    "        beginning = '(' if key == primary_keys[0] else ''\n",
    "        end = '))' if key == primary_keys[-1] else ','\n",
    "        keys_query += f\"{beginning}{key}{end}\"\n",
    "        \n",
    "    query += ' ' + keys_query\n",
    "    \n",
    "    session.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def string_to_date(date):\n",
    "    # convert string to date\n",
    "    return datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "    \n",
    "def string_to_int(string):\n",
    "    # convert string to integer\n",
    "    return int(float(string))\n",
    "\n",
    "def prepare_values(data_types, line):\n",
    "    \"\"\" This function prepares and formats the values to be inserted into a table\n",
    "    \"\"\"\n",
    "    \n",
    "    values = []\n",
    "    for i in range(len(line)):\n",
    "        if line[i]:\n",
    "            values.append(data_types[i][2](line[i]))\n",
    "        else:\n",
    "            values.append(UNSET_VALUE)\n",
    "    values = tuple(values)\n",
    "    \n",
    "    return values\n",
    "\n",
    "def prepare_insert_statement(table_name, columns):\n",
    "    \"\"\" This function prepares a table insertion statement\n",
    "    \"\"\"\n",
    "    \n",
    "    query = f\"INSERT INTO {table_name}\"\n",
    "    for col in columns:\n",
    "        beginning = '(' if col == columns[0] else ''\n",
    "        end = ')' if col == columns[-1] else ','\n",
    "        query += f\"{beginning} {col[0]}{end}\"\n",
    "    query += f\" VALUES({'?,'*(len(columns)-1)}?)\"\n",
    "    \n",
    "    return query\n",
    "\n",
    "def insert_into_table(table_name, columns, filepath, interval=10000):\n",
    "    \"\"\" \n",
    "    This function inserts data into the immigration table.\n",
    "    It specifically does not insert null values into the table.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()    \n",
    "\n",
    "    # open file\n",
    "    for file in glob.glob(filepath):\n",
    "        with open(file, encoding='utf8') as f:\n",
    "\n",
    "            csvreader = csv.reader(f)\n",
    "            # skip header\n",
    "            next(csvreader)\n",
    "\n",
    "            line_num = 1\n",
    "            for line in csvreader:\n",
    "                # prepare and insert values\n",
    "                insert_statement = prepare_insert_statement(table_name, columns)\n",
    "                ps = session.prepare(insert_statement)\n",
    "                values = prepare_values(columns, line)\n",
    "                session.execute(ps, values)\n",
    "                \n",
    "                if line_num%interval == 0:\n",
    "                    clear_output()\n",
    "                    print(f'Loaded up to row {line_num}')\n",
    "                line_num +=1\n",
    "            clear_output()\n",
    "            print(f\"Finished loading data! {line_num-1} rows loaded. \\nExecution took {time.time()-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Create and insert into tables_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data! 127155 rows loaded. \n",
      "Execution took 306.79215598106384 seconds\n"
     ]
    }
   ],
   "source": [
    "create_table('immigration', immigration_columns, immigration_primary_keys)\n",
    "insert_into_table('immigration', immigration_columns, filepath='./clean_data/immigration_data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data! 153560 rows loaded. \n",
      "Execution took 288.31449699401855 seconds\n"
     ]
    }
   ],
   "source": [
    "create_table('temperatures', temperature_columns, temperature_primary_keys)\n",
    "insert_into_table('temperatures', temperature_columns, filepath='./clean_data/temperature_data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data! 2891 rows loaded. \n",
      "Execution took 5.766994953155518 seconds\n"
     ]
    }
   ],
   "source": [
    "create_table('us_demographics', us_demographic_columns, us_demographic_primary_keys)\n",
    "insert_into_table('us_demographics', us_demographic_columns, filepath='./clean_data/us_demographic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data! 55075 rows loaded. \n",
      "Execution took 103.87967848777771 seconds\n"
     ]
    }
   ],
   "source": [
    "create_table('airport_codes', airport_code_columns, airport_code_primary_keys)\n",
    "insert_into_table('airport_codes', airport_code_columns, filepath='./clean_data/airport_code_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "For each table, the checks will verify:\n",
    "- the total number of table rows matches the number of rows from the saved dataframe\n",
    "- the data types of each column matches the definition made before the table's creation\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "def row_number_check(table, dataframe, spark_df=True):\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT count(*) FROM {table} limit 5000000\n",
    "    \"\"\"\n",
    "    rows = session.execute(query)\n",
    "    \n",
    "    table_rows = rows[0].count\n",
    "    if spark_df:\n",
    "        df_length = dataframe.count()\n",
    "    else:\n",
    "        df_length = len(dataframe)\n",
    "        \n",
    "    assert table_rows == df_length, f\"Rows don't match. Table rows: {table_rows}; DF rows: {df_length}\"\n",
    "        \n",
    "    print(f\"Row Number checks passed! Rows: {df_length}\")\n",
    "\n",
    "def convert(lst):\n",
    "    res_dct = map(lambda col: (col[0], [col[1], col[2]]), lst)\n",
    "    return dict(res_dct)\n",
    "\n",
    "def type_checks(table_name, columns):\n",
    "    \n",
    "    column_dict = convert(immigration_data_types)\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT column_name, type from system_schema.columns\n",
    "    WHERE keyspace_name = 'us_immigration'\n",
    "    AND table_name = '{table_name}'\n",
    "    \"\"\"\n",
    "\n",
    "    rows = session.execute(query)\n",
    "\n",
    "    values = []\n",
    "    for row in rows:\n",
    "        assert column_dict[row.column_name][0] == row.type, \\\n",
    "        f\"mismatch between data types for {row.column_name}\"\n",
    "        \n",
    "    print(\"Data type checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Number checks passed! Rows: 127155\n",
      "Data type checks passed!\n"
     ]
    }
   ],
   "source": [
    "row_number_check('immigration',immigration_data)\n",
    "type_checks('immigration', immigration_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Number checks passed! Rows: 153560\n",
      "Data type checks passed!\n"
     ]
    }
   ],
   "source": [
    "row_number_check('temperatures',temperature_data)\n",
    "type_checks('temp', immigration_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Number checks passed! Rows: 2891\n",
      "Data type checks passed!\n"
     ]
    }
   ],
   "source": [
    "row_number_check('us_demographics',us_demographic_data, spark_df=False)\n",
    "type_checks('immigration', immigration_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Number checks passed! Rows: 55075\n",
      "Data type checks passed!\n"
     ]
    }
   ],
   "source": [
    "row_number_check('airport_codes',airport_code_data, spark_df=False)\n",
    "type_checks('immigration', immigration_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Drop the tables before closing out the sessions\n",
    "def droptables(tables):\n",
    "    for table in tables:\n",
    "        session.execute(f'DROP TABLE IF EXISTS {table}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "_Close out the session_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.3 Data dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration Data\n",
    "* cic_id: The CIC ID number\n",
    "* admission_year: year of arrival\n",
    "* applicant_month: month of arrival\n",
    "* applicant_city: country from where the applicant travelled\n",
    "* applicant_residence: applicant's residence location \n",
    "* application_port: port processing the application\n",
    "* arrival_date: string_to_date\n",
    "* applicant_arrival_mode: mode of arrival\n",
    "* port_state: state of port\n",
    "* departure_date: departure date from the US\n",
    "* age: respondent age\n",
    "* visa_code: visa code (business, pleasure, student)\n",
    "* count: count\n",
    "* character_date: string_to_date\n",
    "* visa_post: Department of State where where Visa was issued\n",
    "* occupation: Occupation that will be performed in the US\n",
    "* arrival_flag: admitted or paroled into the US\n",
    "* departure_flag: Departed, lost I-94 or is deceased\n",
    "* update_flag: Either apprehended, overstayed, adjusted to perm residence\n",
    "* match_flag: flag indicating arrival and departure dates match\n",
    "* birth_year: year of birth\n",
    "* date_admitted: date admitted to stay in the US\n",
    "* gender: gender\n",
    "* insurance_num: insurance number\n",
    "* airline: airline used to arrive in the US\n",
    "* admssion_number: admission number\n",
    "* flight_no: flight number of airline used to arrive in the US\n",
    "* visa_type: Class of admission legally admitting the non-immigrant to temporarily stay in the US\n",
    "\n",
    "\n",
    "#### Temperature Data\n",
    "* date: date\n",
    "* average_temperature: average temperature on day\n",
    "* average_temperature_uncertainty: measure of uncertainty about average temperature measure\n",
    "* city: city\n",
    "* country: country\n",
    "* latitude: latitude of city location\n",
    "* longitude: longitude of city location\n",
    "\n",
    "#### US Demographic Data\n",
    "* city: city\n",
    "* state: state\n",
    "* median_age: median age\n",
    "* male_population: male population count\n",
    "* female_population: female population count\n",
    "* total_population: total population count\n",
    "* number_of_veterans: number of veterans\n",
    "* foreign_born: number of foreign born citizens\n",
    "* average_household_size: average household size\n",
    "* state_code: state code\n",
    "* race: ethnic race\n",
    "* count: count\n",
    "\n",
    "#### Airport Code Data\n",
    "* ident: identity code\n",
    "* type: type of airport \n",
    "* name: airport name\n",
    "* elevation_ft: elevation level in feet\n",
    "* continent: continent\n",
    "* iso_country: country\n",
    "* iso_region: region\n",
    "* municipality: municipality\n",
    "* gps_code: gps code\n",
    "* iata_code: iata code\n",
    "* local_code: local code\n",
    "* coordinates: airport location coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Project Write Up\n",
    "\n",
    "The goal for this script was to take data from four different sources, explore it, clean it where relevant and load into an Apache Cassandra database.\n",
    "\n",
    "The rationale for choosing a Apache Cassandra database is threefold:\n",
    "- The loaded data tables do not appear strongly related.\n",
    "- The data loaded relates to April 2016 only is very large already (~3m rows and ~400MB). If more months' data were to be added, the size would quickly increase. A relational database might start to struggle when the whole data fits in the RAM.\n",
    "- This structure would allow the database to consistently scale when needed.\n",
    "\n",
    "More information can be found in section 3.2.\n",
    "\n",
    "I propose the data be updated once a month. The US National Tourism and Trade Office produce the immigration dataset monthly. Hence, a shorter timeframe does not make sense. In addition, it is unlikely that the newly updated data would be required on an urgent basis.\n",
    "\n",
    "A note on incorporating other technologies:\n",
    "- The script is currently set up to extract the data from local storage. This process could be automated by using airflow. Airflow could be scheduled to run the scripts at the desired intervals. In addition, the script could be updated the query the data producers' APIs (if they exist).\n",
    "- Currently, the script uses Spark to process the larger datasets. However, this processing is done locally. If the datasets' size increased, a cluster could be spun up (e.g. Amazon EMR) to handle this processing task. This would start to become more of a concern if any of the dataset's size started to approach the size of the computer's memory.\n",
    "- The script currently spins up the Cassandra cluster locally and does not save the processed tables. It would be best to use a cloud service to set up the cluster and store the data.\n",
    "\n",
    "#### Scenario Planning\n",
    "- The data was increased by 100x: Apache Cassandra would handle this size increase without issues.\n",
    "- The data populates a dashboard that must be updated on a daily basis by 7am every day: The scripts should be run at the end of the previous day to refresh the tables.\n",
    "- The database needed to be accessed by 100+ people: Apache Cassandra achieves high data availability without a guarantee that the data is the latest update. The risk of outdated data would increase with multiple people needing to access the database concurrently. In this case, communicating Cassandra's guarantee of eventual data consistency would be important for end users. On the other hand, Cassandra would allow multiple users to access the database unlike a RMDBS, given their ACID nature, which would lock data if is being acted on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
